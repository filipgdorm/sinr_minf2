{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebook for generating thresholds to subsample 10% of iucn data to pick threshold, same as v1, except we have the same amount of presence and absence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import f1_score, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualFCNet(\n",
       "  (class_emb): Linear(in_features=256, out_features=47375, bias=False)\n",
       "  (feats): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): ResLayer(\n",
       "      (nonlin1): ReLU(inplace=True)\n",
       "      (nonlin2): ReLU(inplace=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (w1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (w2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (3): ResLayer(\n",
       "      (nonlin1): ReLU(inplace=True)\n",
       "      (nonlin2): ReLU(inplace=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (w1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (w2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (4): ResLayer(\n",
       "      (nonlin1): ReLU(inplace=True)\n",
       "      (nonlin2): ReLU(inplace=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (w1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (w2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (5): ResLayer(\n",
       "      (nonlin1): ReLU(inplace=True)\n",
       "      (nonlin2): ReLU(inplace=True)\n",
       "      (dropout1): Dropout(p=0.5, inplace=False)\n",
       "      (w1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (w2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "train_params = torch.load('./pretrained_models/model_an_full_input_enc_sin_cos_hard_cap_num_per_class_1000.pt', map_location='cpu')\n",
    "model = models.get_model(train_params['params'])\n",
    "model.load_state_dict(train_params['state_dict'], strict=True)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load reference from iucn\n",
    "with open(os.path.join('./data/eval/iucn/', 'iucn_res_5.json'), 'r') as f:\n",
    "            data = json.load(f)\n",
    "species_ids = list((data['taxa_presence'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_params['params']['input_enc'] in ['env', 'sin_cos_env']:\n",
    "    raster = datasets.load_env()\n",
    "else:\n",
    "    raster = None\n",
    "enc = utils.CoordEncoder(train_params['params']['input_enc'], raster=raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_locs = np.array(data['locs'], dtype=np.float32)\n",
    "obs_locs = torch.from_numpy(obs_locs).to('cpu')\n",
    "loc_feat = enc.encode(obs_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_of_interest = torch.zeros(len(species_ids), dtype=torch.int64)\n",
    "taxa_ids = torch.zeros(len(species_ids), dtype=torch.int64)\n",
    "for tt_id, tt in enumerate(species_ids):\n",
    "    class_of_interest = np.array([train_params['params']['class_to_taxa'].index(int(tt))])\n",
    "    classes_of_interest[tt_id] = torch.from_numpy(class_of_interest)\n",
    "    taxa_ids[tt_id] = int(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    loc_emb = model(loc_feat, return_feats=True)\n",
    "    wt = model.class_emb.weight[classes_of_interest, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_at_thresh(y_true, y_pred, thresh, type = 'binary'):\n",
    "    y_thresh = y_pred > thresh\n",
    "    return f1_score(y_true, y_thresh, average=type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n"
     ]
    }
   ],
   "source": [
    "output = list()\n",
    "for tt_id, taxa in enumerate(taxa_ids):\n",
    "    wt_1 = wt[tt_id,:]\n",
    "    preds = torch.sigmoid(torch.matmul(loc_emb, wt_1)).cpu().numpy()\n",
    "    taxa = taxa.item()\n",
    "    species_locs = data['taxa_presence'].get(str(taxa))\n",
    "    y_test = np.zeros(preds.shape, int)\n",
    "    y_test[species_locs] = 1\n",
    "\n",
    "    #split into 5% used for setting thresholds 95% for final eval\n",
    "\n",
    "    # Presences\n",
    "    indices_of_ones = np.where(y_test == 1)[0]\n",
    "    subset_size = math.ceil((len(indices_of_ones) * 0.05))\n",
    "    random_indices_ones = np.random.choice(indices_of_ones, subset_size, replace=False)\n",
    "\n",
    "    # Absences\n",
    "    indices_of_zeros = np.where(y_test == 0)[0]\n",
    "    random_indices_zeros = np.random.choice(indices_of_zeros, subset_size, replace=False)\n",
    "\n",
    "    chosen_indices_mask = np.zeros_like(y_test, dtype=bool)\n",
    "    chosen_indices_mask[np.concatenate((random_indices_zeros, random_indices_ones))] = True\n",
    "\n",
    "    thresh_y_test = y_test[chosen_indices_mask]\n",
    "    thresh_preds = preds[chosen_indices_mask]\n",
    "    eval_y_test = y_test[~chosen_indices_mask]\n",
    "    eval_preds = preds[~chosen_indices_mask]\n",
    "    \n",
    "    #calculate thresholds \n",
    "    precision, recall, thresholds = precision_recall_curve(thresh_y_test, thresh_preds)\n",
    "    p1 = (2 * precision * recall)\n",
    "    p2 = (precision + recall)\n",
    "    out = np.zeros( (len(p1)) )\n",
    "    fscore = np.divide(p1,p2, out=out, where=p2!=0)\n",
    "    index = np.argmax(fscore)\n",
    "    thres = thresholds[index]\n",
    "\n",
    "    #evaluate performance\n",
    "    f1 = f1_at_thresh(eval_y_test, eval_preds, thres)\n",
    "    \n",
    "    row = {\n",
    "        \"taxon_id\": taxa,\n",
    "        \"thres\": thres,\n",
    "        \"fscore\": f1,\n",
    "        \"#presence_absence_pairs\": subset_size,\n",
    "    }\n",
    "    row_dict = dict(row)\n",
    "    output.append(row_dict)\n",
    "\n",
    "    if(tt_id%100==0):\n",
    "            print(tt_id)\n",
    "\n",
    "output_pd = pd.DataFrame(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4742468490769256"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pd.fscore.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pd.to_csv('./results/f1_scores/iucn_subset_scores_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sinr_icml_og",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
